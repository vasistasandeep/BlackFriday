---
title: "Black friday"
author: "Sandeep V"
date: "October 8, 2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

##Problem Statement

A retail company "ABC Private Limited" wants to understand the customer purchase behaviour (specifically, purchase amount) against various products of different categories. They have shared purchase summary of various customers for selected high volume products from last month.
The data set also contains customer demographics (age, gender, marital status, city_type, stay_in_current_city), product details (product_id and product category) and Total purchase_amount from last month.
Now, they want to build a model to predict the purchase amount of customer against various products which will help them to create personalized offer for customers against different products.

##Frame the Problem:

Problem Statement - Predict the purchase amount of customer against various products which will help them to create personalized offer for customers against different products.

##Acquire the Data:

```{r}
path <- "C:/Users/vasistas/Documents/From_Mydownloads/PGP-BDA/In_class/2nd_Residency/SVAP_Amit/Assignment/Black_friday"
setwd(path)
```

```{r}
install.packages("data.table")
library(data.table)

#load data using fread
train <- fread("train.csv", stringsAsFactors = T)
test <- fread("test.csv", stringsAsFactors = T)

#No. of rows and columns in Train
dim(train)

dim(test)

str(train)
```
##Refine the Data:

```{r}
#first prediction using mean
sub_mean <- data.frame(User_ID = test$User_ID, Product_ID = test$Product_ID, Purchase = mean(train$Purchase))
#To write into file
write.csv(sub_mean, file = "first_sub.csv", row.names = F)

summary (train)

summary (test)
```
```{r}
#combine data set
test[,Purchase := mean(train$Purchase)]
c <- list(train, test)
combin <- rbindlist(c)
#Purchase variable in the test set so that both data sets have equal number of columns.
```
```{r}
#analyzing gender variable
combin[,prop.table(table(Gender))]
#Age Variable
combin[,prop.table(table(Age))]
#City Category Variable
combin[,prop.table(table(City_Category))]
#Stay in Current Years Variable
combin[,prop.table(table(Stay_In_Current_City_Years))]
#unique values in ID variables
length(unique(combin$Product_ID))
length(unique(combin$User_ID))
#missing values
colSums(is.na(combin))
```
##Transform the Data: 
```{r}
#create a new variable for missing values
combin[,Product_Category_2_NA := ifelse(sapply(combin$Product_Category_2, is.na) ==    TRUE,1,0)]
combin[,Product_Category_3_NA := ifelse(sapply(combin$Product_Category_3, is.na) ==  TRUE,1,0)]
```
```{r}
#impute missing values
combin[,Product_Category_2 := ifelse(is.na(Product_Category_2) == TRUE, "-999",  Product_Category_2)]
combin[,Product_Category_3 := ifelse(is.na(Product_Category_3) == TRUE, "-999",  Product_Category_3)]
```
```{r}
#set column level
levels(combin$Stay_In_Current_City_Years)[levels(combin$Stay_In_Current_City_Years) ==  "4+"] <- "4"

#recoding age groups
levels(combin$Age)[levels(combin$Age) == "0-17"] <- 0
levels(combin$Age)[levels(combin$Age) == "18-25"] <- 1
levels(combin$Age)[levels(combin$Age) == "26-35"] <- 2
levels(combin$Age)[levels(combin$Age) == "36-45"] <- 3
levels(combin$Age)[levels(combin$Age) == "46-50"] <- 4
levels(combin$Age)[levels(combin$Age) == "51-55"] <- 5
levels(combin$Age)[levels(combin$Age) == "55+"] <- 6

#convert age to numeric
combin$Age <- as.numeric(combin$Age)

#convert Gender into numeric
combin[, Gender := as.numeric(as.factor(Gender)) - 1]
```
```{r}
#User Count
combin[, User_Count := .N, by = User_ID]

#Product Count
combin[, Product_Count := .N, by = Product_ID]
```
```{r}
#Mean Purchase of Product
combin[, Mean_Purchase_Product := mean(Purchase), by = Product_ID]

#Mean Purchase of User
combin[, Mean_Purchase_User := mean(Purchase), by = User_ID]
```
```{r}
library(dummies)
combin <- dummy.data.frame(combin, names = c("City_Category"), sep = "_")


#check classes of all variables
sapply(combin, class)

#converting Product Category 2 & 3
combin$Product_Category_2 <- as.integer(combin$Product_Category_2)
combin$Product_Category_3 <- as.integer(combin$Product_Category_3)
```
##Explore the Data:

##ggplot
```{r}
library(ggplot2)

#Age vs Gender
ggplot(combin, aes(Age, fill = Gender)) + geom_bar()
```
```{r}
#Age vs City_Category
ggplot(combin, aes(Age, fill = City_Category)) + geom_bar()
```
```{r}
library(gmodels)
CrossTable(combin$Occupation, combin$City_Category)
```

##Model the Data:

```{r}
#Divide into train and test
c.train <- combin[1:nrow(train),]
c.test <- combin[-(1:nrow(train)),]
```

```{r}
#To eliminate noise in variable Product_Category_1 in train.
c.train <- c.train[c.train$Product_Category_1 <= 18,]
```
```{r}
install.packages("h2o")
library(h2o)
```
```{r}
#To launch the H2O cluster
localH2O <- h2o.init(nthreads = -1)
h2o.init()
```
```{r}
#To transfer the data from R to h2o instance. 
train.h2o <- as.h2o(c.train)
test.h2o <- as.h2o(c.test)
```
```{r}
#check column index number
colnames(train.h2o)
```
```{r}
#dependent variable (Purchase)
y.dep <- 14
#independent variables (dropping ID variables)
x.indep <- c(3:13,15:20)
```
```{r}
regression.model <- h2o.glm( y = y.dep, x = x.indep, training_frame = train.h2o, family = "gaussian")
h2o.performance(regression.model)
```
```{r}
#make predictions
predict.reg <- as.data.frame(h2o.predict(regression.model, test.h2o))
sub_reg <- data.frame(User_ID = test$User_ID, Product_ID = test$Product_ID, Purchase =  predict.reg$predict)

write.csv(sub_reg, file = "sub_reg.csv", row.names = F)
```
```{r}
#Random Forest
system.time(
rforest.model <- h2o.randomForest(y=y.dep, x=x.indep, training_frame = train.h2o, ntrees = 1000, mtries = 3, max_depth = 4, seed = 1122)
)
```
```{r}
#making predictions on unseen data
system.time(predict.rforest <- as.data.frame(h2o.predict(rforest.model, test.h2o)))

#writing submission file
sub_rf <- data.frame(User_ID = test$User_ID, Product_ID = test$Product_ID, Purchase =  predict.rforest$predict)
write.csv(sub_rf, file = "sub_rf.csv", row.names = F)
```
```{r}
#GBM
system.time(
gbm.model <- h2o.gbm(y=y.dep, x=x.indep, training_frame = train.h2o, ntrees = 1000, max_depth = 4, learn_rate = 0.01, seed = 1122)
)
h2o.performance (gbm.model)
```

```{r}
#making prediction and writing submission file
predict.gbm <- as.data.frame(h2o.predict(gbm.model, test.h2o))
sub_gbm <- data.frame(User_ID = test$User_ID, Product_ID = test$Product_ID, Purchase = predict.gbm$predict)
write.csv(sub_gbm, file = "sub_gbm.csv", row.names = F)
```
##Deep Learning in H2O

```{r}
#deep learning models
system.time(
             dlearning.model<- h2o.deeplearning(y = y.dep,
             x = x.indep,
             training_frame = train.h2o,
             epoch = 60,
             hidden = c(100,100),
             activation = "Rectifier",
             seed = 1122
             ) 
```
```{r}
##to check performance
h2o.performance(dlearning.model)
```
```{r}
#making predictions
predict.dl2 <- as.data.frame(h2o.predict(dlearning.model, test.h2o))

#create a data frame and writing submission file
sub_dlearning <- data.frame(User_ID = test$User_ID, Product_ID = test$Product_ID, Purchase = predict.dl2$predict)
write.csv(sub_dlearning, file = "sub_dlearning_new.csv", row.names = F)
```

```{r}
dim(sub_dlearning)
summary(sub_dlearning)
plot(sub_dlearning)
```
##Communicate the insight 
The modelling is based at multiple level.

The data set has two parts: 
Train data set contains 550068 observations. 
Test data set contains 233599 observations.

Frame the Problem: We identified the key question i.e, to Predict the purchase amount of customer against various products which will help them to create personalized offer for customers against different products.

Data is explored with data.table and ggplot.

Model building is done based on following algorithm: 

- First Sub

User_ID	Product_ID	Purchase
1000004	P00128942	9263.968713
1000009	P00113442	9263.968713
1000010	P00288442	9263.968713
1000010	P00145342	9263.968713
1000011	P00053842	9263.968713
1000013	P00350442	9263.968713
1000013	P00155442	9263.968713
1000013	P0094542	9263.968713
1000015	P00161842	9263.968713

- Regression

User_ID	Product_ID	Purchase
1000004	P00128942	12074.30754
1000009	P00113442	9951.082602
1000010	P00288442	8489.481369
1000010	P00145342	7848.50069
1000011	P00053842	8704.757697
1000013	P00350442	10886.20154
1000013	P00155442	11081.23712
1000013	P0094542	10686.19786
1000015	P00161842	10362.89892


- Random Forest 

User_ID	Product_ID	Purchase
1000004	P00128942	14532.00892
1000009	P00113442	11563.29175
1000010	P00288442	7295.14836
1000010	P00145342	6833.611735
1000011	P00053842	6943.117187
1000013	P00350442	12604.21932
1000013	P00155442	13183.52177
1000013	P0094542	11970.10074
1000015	P00161842	12037.35551


- GBM

User_ID	Product_ID	Purchase
1000004	P00128942	17362.76222
1000009	P00113442	11900.00468
1000010	P00288442	6480.229421
1000010	P00145342	2873.079642
1000011	P00053842	2607.002945
1000013	P00350442	12372.82079
1000013	P00155442	12892.22349
1000013	P0094542	11567.97527
1000015	P00161842	14163.61016


- Deep Learning

User_ID	Product_ID	Purchase
1000004	P00128942	17016.29263
1000009	P00113442	11728.05768
1000010	P00288442	7071.642112
1000010	P00145342	2694.551087
1000011	P00053842	2287.079024
1000013	P00350442	10745.28414
1000013	P00155442	12266.2726
1000013	P0094542	10186.26856
1000015	P00161842	14998.63473


These models train data for prediction but at high CPU utilization. THis is monitored using H2O lib.

The model outputs we can see refining and different modelling techniques provides better outputs.

